{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3234e5",
   "metadata": {},
   "source": [
    "## Sitting Posture Coach\n",
    "\n",
    "https://www.sitting-posture.coach\n",
    "\n",
    "The posture model is trained in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d767c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982a3ce",
   "metadata": {},
   "source": [
    "Load the data using `keras.preprocessing.image_dataset_from_directory`. Training and validation data are in seperate directories, inside these directories are subdirectories `0` and `1` containing respectively bad and good sitting posture images. All images are 128x128 pixels and cropped around the persons head and shoulders. Take a look in `data.py` to see how these are generated and preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5d8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = keras.preprocessing.image_dataset_from_directory('data/train', batch_size=8, image_size=(128, 128))\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory('data/val', batch_size=8, image_size=(128, 128))\n",
    "\n",
    "preprocessing_train = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.5),\n",
    "    \n",
    "])\n",
    "\n",
    "preprocessing_val = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (preprocessing_train(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (preprocessing_val(x), y))\n",
    "\n",
    "x, y = next(iter(train_ds))\n",
    "print(x.shape, y)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(8):\n",
    "    image = x[i]\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991045fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(128, 128, 3))\n",
    "x = layers.Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=3e-4), loss='binary_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e78131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcb4f3",
   "metadata": {},
   "source": [
    "The trained model is saved directly in TensorFlow JavaScript (TFJS) format, in the right location in the frontend directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf07514",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, '../sitting-posture-coach/frontend/tfjs_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bebef6d",
   "metadata": {},
   "source": [
    "Results on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all, y_pred_all = [], []\n",
    "for x, y in val_ds:\n",
    "    y_pred = model.predict(x)\n",
    "    y_all.append(y)\n",
    "    y_pred_all.append(y_pred)\n",
    "    print(f'label: {y}')\n",
    "    print(f'prediction: {y_pred}')\n",
    "y_all = np.concatenate(y_all).astype(np.float32)\n",
    "y_pred_all = np.concatenate(y_pred_all)[:, 0]\n",
    "\n",
    "sns.violinplot(x=y_all, y=y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712ce15a",
   "metadata": {},
   "source": [
    "Some code to generate saliency maps. What is the model looking for in the image to make a decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9072ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = model(x)\n",
    "    # y_logit = tf.math.log(y / (1 - y))\n",
    "    grad = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c39744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, grad_image) in enumerate(zip(x, grad)):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    plt.imshow(0.5 + grad_image * 50)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbf287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "2f53ab63e95d34222b9541777a2a11e3faeac671ebf05f5f7ddff4e0d94fe243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
